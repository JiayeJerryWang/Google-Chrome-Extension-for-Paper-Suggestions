1854
IEICE
TRANS.
INF.
&amp;
SYST.,
VOL.E94–D,
NO.10
OCTOBER
2011
INVITED
PAPER
Special
Section
on
Information-Based
Induction
Sciences
and
Machine
Learning
A
Short
Introduction
to
Rank
Hang
LI†a),
Nonmember
SUMMARY
rank
refers
machine
learning
techniques
for
training
the
model
in
a
ranking
task.
is
useful
many
applications
Information
Retrieval,
Natural
Language
Processing,
Data
Mining.
Intensive
studies
have
been
conducted
problem
signiﬁcant
progress
has
made
[1],
[2].
This
short
paper
gives
an
in-
troduction
rank,
it
speciﬁcally
explains
fundamental
problems,
existing
approaches,
future
work
of
rank.
Several
methods
using
SVM
are
described
details.
key
words:
information
retrieval,
natural
language
pro-
cessing,
1.
Ranking
Problem
can
be
employed
wide
variety
Retrieval
(IR),
Lan-
guage
Processing
(NLP),
Mining
(DM).
Typi-
cal
document
expert
search,
def-
inition
collaborative
ﬁltering,
question
answering,
keyphrase
extraction,
summarization,
ma-
chine
translation
Without
loss
generality,
we
take
retrieval
as
example
this
article.
Document
task
follows
(Fig.
1).
The
system
maintains
collection
documents.
Given
query,
retrieves
documents
containing
query
words
from
collection,
ranks
documents,
returns
top
ranked
performed
by
f(q,
d)
sort
where
q
denotes
d
document.
Traditionally,
created
with-
out
training.
In
BM25
model,
example,
assumed
that
represented
conditional
probability
distri-
bution
P(r|q,
r
takes
1
or
0
value
being
relevant
irreverent,
denote
respectively.
Model
IR
(LMIR),
distribu-
tion
P(q|d).
models
calculated
with
appearing
document,
thus
no
needed
(only
tuning
small
number
param-
eters
necessary)
[3].
new
trend
recently
arisen
particularly
web
is,
employ
learn-
ing
automatically
construct
d).
motivated
facts.
At
Manuscript
received
December
31,
2010.
revised
April
15,
2011.
†The
author
Microsoft
Research
Asia,
No.5
Dan
Ling
St.,
Haidian,
Beijing,
100080,
China.
a)
E-mail:
hangli@microsoft.com
DOI:
10.1587/transinf.E94.D.1854
Fig.
retrieval.
2
there
signals
which
represent
rele-
vance,
anchor
texts
PageRank
score
page.
Incorporating
such
into
constructing
us-
becomes
choice.
search
engines,
large
amount
log
data,
click
through
accumulated.
makes
possible
derive
data
au-
tomatically
create
model.
fact,
become
one
technologies
modern
search.
We
describe
issues
ranking,
including
testing,
labeling,
feature
con-
struction,
evaluation,
relations
ordinal
classiﬁca-
tion.
1.1
Training
Testing
supervised
testing
phases
(see
2).
consists
queries
Copyright
c⃝
Institute
Electronics,
Communication
Engineers
LI:
SHORT
INTRODUCTION
TO
LEARNING
RANK
1855
Each
associated
relevance
respect
also
given.
sev-
eral
ways.
Here,
most
widely
used
approach
assume
label,
while
labels
several
grades
(levels).
higher
grade
has,
more
is.
Suppose
Q
set
D
docu-
ment
set.
Y
=
{1,
2,
·
,
l}
label
set,
grades.
There
exists
total
order
between
l
≻
−
1,
de-
notes
relation.
Further
suppose
{q1,
q2,
qm}
qi
i-th
query.
Di
{di,1,
di,2,
di,ni}
yi
{yi,1,
yi,2,
yi,ni}
qi,
ni
sizes
yi;
di,
j
j-th
Di;
yi,
∈
representing
degree
qi.
original
denoted
S
{(qi,
Di),
yi}m
i=1.
vector
xi,
φ(qi,
j)
each
query-document
pair
(qi,
j),
i
m;
ni,
φ
functions.
That
say,
features
deﬁned
functions
pair.
For
typical
Letting
xi
{xi,1,
xi,2,
xi,ni},
′
{(xi,
yi)}m
Here
x
X
⊆
ℜd.
aim
train
(local)
f(x)
assign
given
d,
equivalently
x.
More
gener-
ally,
consider
global
F(q,
D)
F(x).
local
outputs
sin-
gle
score,
list
scores.
Let
identiﬁed
integers
ni}.
deﬁne
permutation
(ranking
list)
πi
bijection
ni}
itself.
use
Πi
all
permutations
Di,
πi(
(or
position)
(i.e.,
πi.
nothing
but
select
scores
f(qi,
di).
test
qm+1
asso-
ciated
Dm+1.
T
{(qm+1,
Dm+1)}.
xm+1,
trained
Dm+1,
them
based
scores,
give
output
πm+1.
similar
to,
diﬀerent
conventional
classiﬁcation
regression.
Query
its
doc-
uments
form
group.
groups
i.i.d.
instances
within
group
not
data.
function
equiva-
lently,
derived
1.2
Labeling
Currently
two
ways
ﬁrst
human
judgments
second
derivation
explain
ap-
proach
here.
Explanations
found
approach,
ran-
domly
selected
system.
Sup-
pose
multiple
systems.
Then
submitted
systems
collected.
As
result,
Human
judges
then
asked
make
pairs.
Relevance
usually
at
ﬁve
levels,
perfect,
excellent,
good,
fair,
bad.
viewpoint
average
users.
if
‘Microsoft’,
page
microsoft.com,
‘perfect’.
Furthermore,
Wikipedia
about
‘excellent’,
so
on.
Labels
rel-
evance
assigned
Rele-
vance
judgment
majority
voting
ducted.
Benchmark
sets
released
[4].
1.3
Evaluation
evaluation
performance
carried
comparison
lists
ground
truth.
measures
other
ﬁelds.
These
include
NDCG
(Normalized
Discounted
Cu-
mulative
Gain),
DCG
(Discounted
Cumulative
MAP
(Mean
Average
Precision),
Kendall’s
Tau.
(permutation)
(grades)
Di.
[5]
good-
ness
labels.
Speciﬁcally,
position
k
as:
DCG(k)
�
j:πi(j)≤k
G(
j)D(πi(
j)),
Gi(·)
gain
Di(·)
dis-
count
function,
summation
taken
over
positions
represents
cumulative
accessing
discounts
positions.
normalized
NDCG(k)
G−1
max,i(k)
Gmax,i(k)
normalizing
factor
chosen
1856
Table
Examples
calculation.
Perfect
Formula
Explanation
(3,
3,
1)
grades:
(7,
7,
Eq.
(1)
gains
(1,
0.63,
0.5,
·)
(2)
11.41,
12.91,
(3)
(1/7,
1/11.41,
1/12.91,·
normalizers
(1,1,1,·
(4)
Imperfect
(2,
7.41,
8.91,
(0.43,
0.65,
0.69,
perfect
π∗
’s
al-
higher.
Note
rankings
normally
exponential
grade.
satisfaction
access-
exponentially
increases
when
increases.
2yi,j
(grade)
discount
logarith-
mic
position.
logarithmically
decreases
access
D(πi(
j))
log2(1
+
Hence,
j)).
values
further
aver-
aged
queries.
examples
calculating
lists.
(DCG)
eﬀect
giving
high
high.
rankings,
always
one,
imperfect
less
than
one.
another
measure
IR.
MAP,
levels:
0.
Precision
AP
�ni
j=1
P(
value,
irrelevant.
k:πi(k)≤πi(j)
yi,k
precision
until
either
0,
‘precision’
deﬁned.
Av-
erage
averaged
Mean
(MAP).
1.4
Relation
Ordinal
Classiﬁcation
(also
known
regression)
diﬀerent.
input
y
grade,
classes
order.
goal
mainly
scoring
f(x).
assigns
real
determines
thresholds.
partitions
axis
intervals
aligns
interval
It
falls
cares
accurate
ordering
objects,
classiﬁcation,
ordered-categorization
objects.
exam-
ple
product
rating.
movie,
stars
(ratings)
movie.
case,
correct
assignment
critical.
contrast,
objective
cor-
rectly
related
although
sometimes
labeled
or-
dinal
classiﬁcation.
vary
available
only
weakly
ments
available.
2.
Formulation
formalize
space
(feature
space)
consisting
vectors,
consist-
element
vectors
P(X,
Y)
unknown
joint
distribution
random
variable
value.
Assume
F(·)
mapping
learn
ˆF(x)
1857
(x1,
y1),
(x2,
y2),
.
(xm,
ym).
instance
comprised
corresponding
(i
m).
m
instances.
F(x)
written
(
f(x1),
f(x2),
f(xn))
(y1,
y2,
yn).
fea-
ture
objects
ranked.
n
L(·,
utilized
evaluate
predic-
result
F(·).
First,
ac-
cording
F(x),
results
evaluated
their
y.
If
higher,
will
small.
Otherwise,
large.
L(F(x),
y).
slightly
statistical
tasks,
sense
sorting.
risk
R(·)
expected
Y),
R(F)
X×Y
y)dP(x,
calculate
empirical
follows,
ˆR(F)
i=1
L(F(xi),
yi).
minimization
tasks.
mini-
mization
could
diﬃcult
due
nature
(it
continuous
uses
sorting).
surrogate
func-
L′(F(x),
follows.
ˆR′(F)
L′(F(xi),
introduce
regularizer
conduct
regularized
risk.
cases,
(regularized)
empiri-
loss.
adopt
formulation
IR,
degrees
practice,
f(·).
very
large,
even
inﬁnite.
(loss
function)
however,
concerned
results.
true
those
Gain)
Precision).
y)
1.0
NDCG.
(NDCG
loss)
sorting
it,
lead
approaches
pointwise
loss,
pairwise
listwise
squared
Subset
Regression
point-
wise
[6].
call
because
single
f(xi)
yi)2.
actually
upper
bound
Pairwise
losses
hinge
logistic
pairs
Rank-
[7],
RankBoost
[8],
RankNet
[9],
They
bounds
[10].
n−1
j=i+1
φ(sign(yi
yj),
f(xj)),
L′
yj
function.
Listwise
just
like
functions,
directly
Diﬀerent
exploited
methods.
ple,
AdaRank
exp(−NDCG),
basis
Ob-
viously,
3.
Pointwise
Approach
creation)
transformed
regression,
applied.
Therefore,
structure
ignored
approach.
includes
[6],
McRank
[11],
Prank
[12],
OC
[13].
last
detail.
3.1
method
proposed
Shashua
Levin
[13]
utilizes
parallel
hyperplanes
Their
method,
referred
article,
learns
margin
principle.
implementation,
tries
maximize
ﬁxed
mar-
gin
adjacent
(grades)†.
ℜd
maximizes
sum
margins.
1858
3
oridinal
Y.
object
vector)
x,
predict
problem.
linear
(parallel
hyperplanes)
⟨w,
x⟩−br,
(r
l−1)
prediction,
w
weight
br
ℜ,
l)
biases
satisfying
b1
≤
bl−1
bl
+∞.
correspond
x⟩−br
separating
r+1,
l−1).
Figure
illustrates
satisﬁes
x⟩
br−1
≥
&lt;
r,
l).
write
minr∈{1,···,l}{r|⟨w,
0}.
69–90
(1999)
1999
Kluwer
Academic
Publishers.
Manufactured
Netherlands.
An
Statistical
Approaches
Text
Categorization∗
YIMING
YANG
yiming@cs.cmu.edu
School
Computer
Science,
Carnegie
Mellon
University,
Pittsburgh,
PA
15213-3702,
USA
Received
October
28,
1997;
Revised
May
13,
1998;
Accepted
July
27,
1998
Abstract.
focuses
comparative
wide-range
text
categorization
methods,
cluding
previously
published
Reuters
corpus
additional
experiments.
controlled
study
three
classiﬁers,
kNN,
LLSF
WORD,
was
examine
impact
conﬁguration
vari-
ations
versions
observed
classiﬁers.
Analysis
evidence
suggest
some
were
signiﬁcantly
affected
inclusion
portion
unlabelled
mading
difﬁcult
interpret
leading
considerable
fusions
literature.
Using
exclude
twelve
compared
indirectly.
indirect
compararions,
WORD
baselines,
since
they
ex-
clude
observation,
neural
network
had
best
performance;
except
Naive
Bayes
algorithms
relatively
well.
Keywords:
categorization,
algorithms,
study,
(TC)
assigning
predeﬁned
categories
free
ments.
growing
applied
recent
years,
regression
(Fuhr
et
al.
1991,
Yang
Chute
1994),
near-
est
neighbor
classiﬁers
(Creecy
1992,
Bayesian
probabilistic
(Tzeras
Hartman
1993,
Lewis
Ringuette
1994,
Moulinier
1997),
decision
trees
inductive
rule
gorithms
(Apte
Cohen
Singer
1996,
1996),
networks
(Wiener
1995,
Ng
1997)
on-line
(Cohen
1996).
With
available,
cross-method
evalua-
increasingly
important
identify
state-of-the-art
categorization.
However,
without
uniﬁed
methodology
evaluations,
comparisons
different
difﬁcult.
Ideally,
researchers
would
common
comparable
perfor-
mancemeasurestoevaluatetheirsystems,
orwouldallowtheirsystemstobeevaluatedunder
carefully-controlled
conditions
fashion
Conference
∗This
research
supported
part
NIH
grant
LM-05714
NSF
IRI9314992.
70
(TREC).
reality,
far
ideal.
Cross-method
attempted
literature,
often
scale
these
overly-general
statements
insufﬁcient
observa-
tions,
provide
little
insight
range
approaches.
alternative
small-scale
integrate
carefully
analyzing
establishing
cross-collection
cross-experiment
integration.
solution
TREC-like
well
contribute
insights
individual
studies.
effort
direction.
serious
TC
evaluations
lack
standard
collections.
Even
chosen,
still
inconsistent
variations.
commonly
news
story
corpus,
least
versions,
depending
how
training/test
divided,
subsets
forth.
conﬁgurations
growing.
unclear
whether
reported
other.
variations
experiments
Reuters.
shown
5.2,
certain
do
strong
impact,
not.
underlying
reason
analyzed.
Another
issue
comparability
Many
used,
recall
precision,
accuracy
error,
break-even
point
F-measure,
micro-average
macro-average
binary
11-point
category
forth
deﬁnitions).
designed
aspect
system;
none
convey
identical
information.
Which
suitable
categorization?
How
measures?
ques-
tions
addressed
applying
bi-
nary
assignment.
show
both
types
informative
complementary
baseline
classiﬁer,
reasonably
(indirectly)
compare
per-
formance
among
across
classiﬁer.
divided
six
sections
addition
introduction.
describes
paper.
introduces
analyzes
evaluation.
4
novel
LLSF.
5
reports
our
together
Finally,
summarize
conclusions
6.
AN
EVALUATION
OF
STATISTICAL
APPROACHES
71
Classiﬁers
reuters
2.1.
whose
various
literature
(Hayes
Weinstein
1990,
Apte
Wiener
Pedersen
1997,
1997).1
results,
present
brieﬂy
below,
grouped
roughly
according
theoretical
foundations
technical
characteristics.
CONSTRUE
developed
Group,
earliest
sys-
tem
1990).
Impressive
(about
90%
average)
sub-
(3%)
corpus.
major
difference
considered
manually
domain-
speciﬁc
application-speciﬁc
rules
Adapting
application
domains
costly
labor-intensive.
Decision
tree
(DTree)
well-known
automatic
induction
(Quinlan
1986,
Mitchell
Applied
DTree
criterion,
occurrence
word
combinations
(using
IND
package)
(Lewis
1994)
C4.5)
(Moulinier
(NaiveBayes)
commonly-used
cat-
egorization
(Mitchell
basic
idea
probabilities
estimate
naive
assumption
independence.
simplicity
computation
NaiveBayes
classiﬁer
efﬁcient
complexity
non-naive
does
predictors.
(1994)
(1997),
4.
Inductive
Disjunctive
Normal
Form
(DNF)
tested
WASP-1,
RIPPER
CHARADE
DNF
equal
power
DTrees
theory
Empirical
proaches,
rarely
(1994).
5.
Neural
(NNet)
(1995)
convenience,
former
(developed
Xerox
PARC)
NNet.PARC
paper;
latter
named
CLASSI.
Both
separate
per
category,
72
non-linear
complex
singular
category.
PARC
tried
perceptron
three-layered
addition.
networks,
subset
CLASSI
perceptrons.
Rocchio
classic
vector-space-model
routing
ﬁltering
Applying
prototype
belonging
positive
weight,
remaining
negative
weight.
By
summing
up
positively
negatively
weighted
obtained.
easy
implement
computation,
potential
weakness
centroid
consequently,
perform
naturally
clusters.
7.
stands
Linear
Least
Squares
Fit,
(Yang
1992).
multivariate
learned
categories.
input/output
(consisting
weights),
(with
weights)
solving
least-squares
ﬁt
obtain
matrix
word-category
coefﬁcients.
deﬁnes
arbitrary
weights,
obtained
8.
Sleeping
Experts
(EXPERTS)
On-line
aims
reduce
compu-
tation
phase
applications.
EXPERTS
updates
weights
n-gram
phrases
incrementally.
9.
kNN
k-nearest
nearest
neighbors
top-ranking
similarity
classiﬁed
categories,
ranking.
10.
simple,
non-learning
algorithm
matching
names.
purpose
simple
quantitatively
much
improvement
conventionalvectorspacemodelisusedforrepresentingdocumentsandcategorynames
(each
name
treated
bag
words),
SMART
(Salton
1989)
engine.
73
types:
independent
m-ary
(m
&gt;
2)
YES/NO
independently
decisions
Of
listed
above,
CONSTRUE,
DTree,
NaiveBayes,
DNF,
NNet.PARC,
CLASSI,
Rocchio,
hand,
typically
shared
producing
candidate
conﬁdence
candidate;
per-category
(if
desired)
thresholding
primarily
algorithmic
solutions
converting
decisions,
possible,
principle,
produce
meaningfully
com-
pared
effectively
combine
well-understood
stage
research.
2.2.
20,000
newswire
stories
period
1987
1991.
(Reuters-22173)
provided
Inc.
(CGI)
1990
varying
division
summarizes
versions.
version
called
Reuters-21450),
prepared
contains
(version
723
split
chronologically
contiguous
chunks;
early
training,
later
testing.
113
One
peculiarity
Reuters-22450
unlabeled
(47%)
(58%)
sets.
randomly
belong
Examination
Version
(Prepared
by)
UniqCate
TrainDocs
TestDocs
(Labelled
TestDocs)
182
21,450
(80%)
(Lewis)
14,704
6,746
(42%)
2.2
(Yang)
7,789
3,309
(100%)
(Apte)
93
(PARC)
9,610
3,662
74
happen
unlabelled.2
exactly
should
labelled
To
facilitate
cate-
gorization
same
removed.
constructed
SWAP-1
removing
restricting
training-set
frequency
1994).3
PARC,
1995).
drawn
eliminating
rare
Instead
taking
chunks
slices
overlap
temporally.
numbered,
odd-numbered
testing.4
discussed
automated
assignments.
What
type
preferable
depends
user
interaction,
useful,
fully
ﬁne.
assuming
particular
mind,
evaluating
paper,
usage;
offer
3.1.
Performance
Category
ranking-based
systems:
recall,
averageprecision.
Givenaclassiﬁerwhoseinputisadocument,
andwhoseoutputisaranked
computed
any
threshold
list:
“categories
found”
means
above
threshold.
adapt
procedure
interpolated
McGill
1983),
below:
75
compute
found.
thresholds
0%,
10%,
20%,
100%,
highest
“representative”
left
boundary
interval.
exact
exists,
closest
terms
recall.
empty,
default
zero.
Interpolation:
thresholds,
replace
representative
preci-
sion
Per-interval
Averaging:
per-document
points
step
11
per-interval
Global
single-numbered
(“11-pt
AVGP”).
3.2.
assignments
two-way
contin-
gency
table
(Table
four
cells:
—
cell
counts
correctly
category;
b
incorrectly
c
rejected
Conventional
contingency
tables.
(r),
(p),
fallout
f
),
(Acc)
error
(Err):
•
a/(a
c)
otherwise
undeﬁned;
p
b)
b/(b
Acc
(a
d)/n
0;
Err
(b
c)/n
table.
YES
No
Assigned
NO
76
meth-
ods,
namely
macro-averaging
micro-averaging.
Macro-averaged
computing
tables
averaging
means.
Micro-averaged
mance
creating
sums
cells
tables,
micro-averaged
distinction
Micro-average
every
therefore
(more
precisely,
document/category
pairs).
Likewise,
regard-
frequency,
average.
3.3.
BEP
F-measure
Some
may
misleading
examined
alone.
trivial
says
unacceptably
low
precision.
Conversely,
rejects
fall-out,
sacriﬁce
extreme.
Usually,
exhibits
trade-off
internal
parameters
adjusted;
sacriﬁcing
vice-versa.
tuned
(BEP)
1994).
evaluations.
cannot
equal,
BEP.
interpolation
apart,
reﬂect
behavior
F1
measure,
van
Rijsbergen
(1979),
choice
measure:
2rp/(r
p).
balances
way
general
Fβ(r,
p)
(β2
1)pr
β2
β
parameter
allowing
differential
weighting
(p)
(r).
optimization
criterion
decisions.
Its
maximized
close;
otherwise,
smaller
dominates
F1.
noticed
variable.
(at
deﬁnition),
2r2/2r
=r
p.
optimal
restricts
kinds
77
measured
via
system’s
deﬁnitely
better
performer
(when
balanced
main
consideration),
converse
necessarily
true.
3.4.
Although
categorizations
systems,
pitfall
following
pitfall.
having
1.2/93
1.3%.
Consequently,
(micro
macro,
equal)
rate
1.3%
98.7%.
rejector
sensible
effectiveness
usefulness
thenumberofcategoriesislargeandtheaveragenumberofcategoriesperdocumentissmall.
illustrated
OHSUMED
(Hersh
233,445
indexed
14,321
unique
categories;
13
0.1%
99.9%.
system,
tend
trivially
reject
rate.
Fundamentally,
difﬁculties
arises
deﬁnitions.
Unlike
n,
divisor.
change
(true
positive)
negative)
(likewise
error).
maximum
(neither
larger
question).
zero
effect
3.5.
Comparative
analysis
Now
c);
small,
furthermore
quantity
constant
question.
78
incorrect
1/(a
c),
1/n
proper
erroneous
words,
sensitive
error.
sensitivity
deno-
minator,
whichcanbequitelarge.However,
iftheclassiﬁerisperformingwell,
thenthevalue
misclassiﬁcation
documents;
are,
errors
process.
Fallout
suffers
error;
denominator
Thus,
recognized
classiﬁer;
errors,
rejection
algorithm,
acceptance
algorithm.
BEP,
F1,
good
interpolation,
sufﬁciently
close
actual
values.
Accuracy
insensitive
variances,
return
near-optimal
itself
mean
completely
useless
insightful
coupled
general,
measuring
instead
compressing
score.
Experimental
design
LLSF,
explore
aspects:
variability
classiﬁers;
decisions;
reﬂecting
behavior;
scalability
larger/harder
application,
i.e.,
collection.
mentioned
WORD.
79
4.1.
Preprocessing
selection
bench-marking
1989),
preproces-
sor
stop
stemming,
term
weighting,
after
stemming.
phrasing
option
avail-
able
term-weighting
schemes
within-document
(TF)
Inverted
Frequency
(IDF)
options
tested,
“ltc”,
“atc”,
“ntc”,
etc.
SMART’s
notation.
produced
(“ltc”
cases)
comparisons.
Feature
next
removed
SMART.
attempts
remove
non-informative
improve
computational
complexity.
efﬁciency
especially
computationally
intractable
(in
phase)
Tractability
crucial
improved
noise
reduction
desirable.
Five
criteria
gain,
mutual
exclusion,
χ2
statistic,
strength;
thorough
elsewhere
Pederson
1997).
statistic
effective,
yielded
On
χ2-based
reduced
vocabulary
24,858
2,485.
Correspondingly,
93%
0.81
0.85
F1-measure.
selection)
Aggressive
chance
names
Automatic
Multinomial
Topic
Models
Qiaozhu
Mei,
Xuehua
Shen,
Chengxiang
Zhai
Department
Science
University
Illinois
Urbana-Champaign
Urbana,IL
61801
{qmei2,xshen,czhai}@uiuc.edu
ABSTRACT
distributions
frequently
topics
common,
chal-
lenge
topic
mining
multinomial
accurately
discovered
topic.
So
far,
generated
subjective
way.
propose
automat-
ically
labeling
cast
involving
minimizing
Kullback-Leibler
divergence
maximizing
be-
tween
Experiments
done
genres.
ods
quite
eﬀective
generate
meaningful
interpreting
models.
Our
PLSA,
LDA,
Categories
Subject
Descriptors:
H.3.3
[Informa-
Search
Retrieval]:
General
Terms:
Algorithms
models,
tion,
modeling
attracted
attention
[11,
4,
22,
9,
16,
18,
14,
24]
broad
applications,
includ-
extracting
scientiﬁc
[9,
2],
temporal
[17,
24],
spatiotemporal
[16,
18],
author-
[22,
opinion
extraction
[28,
16],
infor-
mation
25].
Common
unigram
model)
text.
Permission
digital
hard
copies
personal
classroom
granted
fee
distributed
proﬁt
commercial
advantage
bear
notice
full
citation
copy
republish,
post
servers
redistribute
lists,
requires
prior
permission
and/or
fee.
KDD’07,
August
12–15,
2007,
San
Jose,
California,
USA.
2007
ACM
978-1-59593-609-7/07/0008
...$5.00.
side
extracted
col-
lection
abstracts
database
“view”,
“materialized”,
“warehouse,”
intuitively
captures
“ma-
terialized
view.”
regarded
proposed,
extract
interesting
tributions
meaningful,
challenge
accu-
rately
meaning
Indeed,
gen-
erally
understand
merely
distribution,
familiar
source
answer
questions
“What
about?”
“How
an-
words?”.
semantics
topics,
modeling,
people
generally
prim-
itive
manner
24].
neither
satisfactory.
Consider
follow-
literature:
Variant
views
0.10
Top
views,
view,
materialized,
view
maintenance,
warehouse,
materialized
0.05
Human:
warehouse
maintenance
0.03
Single
Term:
maintenance;
0.02
Phrase:
summary
Sentence:
Materialized
multi-query
1:
someone
domain
infer
terms.
Similar
use-
ful
coherent
“insulin
glucose
mice
diabetes
hor-
mone”1
medical
science,
audience.
Manual
own
problems.
understandable
capture
1),
lot
eﬀort
1www.cs.cmu.edu/∼lemur/science/topics.html,
26
490
Track
Paper
manual
easily
ased
towards
user’s
opinions.
Moreover,
relying
apply
online
tasks
summarizing
Thus
highly
desirable
mean-
ingful
interpretations
topics.
knowl-
edge,
automati-
cally
tribution
few
suﬀer
topic?
Presumably,
user,
cap-
topic,
distinguish
choices
linguistic
components
labels,
terms,
phrases,
sentences.
Ta-
ble
too
combined
sentence,
speciﬁc,
extremes,
phrase
coher-
ent
concise
enough
understand,
time,
over-
manually,
prefer
phrases.
Intuitively,
choose
must
“seman-
tic
distance”
challenging.
solve
se-
mantics
casting
volving
tribution,
mu-
tual
genres
news).
re-
sults
interpret-
plied
post-processing
long
words.
limited
models;
management
estimated,
clusters
switching
context
seman-
distance
measured,
tent
variation
contexts,
us
views.
alterative
contextual
[18].
rest
organized
Sec-
formally
multi-
nomial
proba-
bilistic
generating
followed
5,
cussion
6,
PROBLEM
FORMULATION
latent
collec-
distributions,
informally,
semantic
now
labeling.
begin
series
Deﬁnition
(Topic
Model)
θ
C
{p(w|θ)}w∈V
V
Clearly,
w∈V
p(w|θ)
semantically
co-
herent
collectively
theme.
“SVM”
“supporting”,
“vector”
“kernel.”
Label)
“label”,
l,
θ,
sequence
mantically
covers
θ.
Words,
sentences
valid
under
deﬁnition.
reasonable
“sup-
porting
machine.”
(Relevance
Score)
s(l,
θ),
l1
l2
s(l1,
θ)
s(l2,
θ).
deﬁnitions,
La-
beling
follows:
L
{l1,
...,
lm},
s(li,
s,
Lθ
{lθ,1,
lθ,n}
deﬁnition
generalized
Θ
{θ1,
θk}
lm}
Li
{li,1,
li,ni},
θi.
need
scenarios,
accepted
(e.g.,
Gene
Ontology
entries
biological
topics).
generally,
la-
bels
reference
themes
mining,
491
KDD
conference
proceedings.
mined
ﬂow
label-
collection;
ﬁnding
function;
w.r.t.
model;
ones
challenges
solved
automatically.
under-
standable,
relevant,
covering
whole
well,
discriminative
knowledge,
candi-
date
non-trivial.
Since
representations,
semantics.
label.
relevance,
ensure
cover
diﬀerence
section,
PROBABILISTIC
TOPIC
LABELING
understandable,
cov-
preprocessing
step,
ﬁnally
selec-
address
inter-topic
discrimination
intra-topic
coverage
Candidate
Label
Generation
sentences,
appear
appropriate
C,
bels.
Phrase
generation
[7,
26,
6].
approaches:
Chunking/Shallow
Parsing:
Chunking
(Shallow
Pars-
ing)
technique
processing,
identifying
“chunks”
chunker
operates
speech
tags,
tags
chunking
grammar,
work,
chunks/phrases
NLP
grammatical
meaningful.
heavily
do-
articles,
scien-
tiﬁc
processing
ology
computer
science
publications.
Ngram
Testing:
ngrams
tests.
ngram
co-occur
other,
likely
n-word
phrase.
collocation/phrase
15].
rely
[7].
Others
hypothesis
techniques.
null
hy-
pothesis
assumes
“the
independent”,
statistics
posed
signiﬁcance
violating
hypothe-
sis.
Two
famous
showing
Test
Student’s
T-Test
[15].
require
applicable
ad
hoc
domains/topics.
disadvantage
linguisti-
works
bigrams.
experiments,
tract
3.2
Semantic
Scoring
semantical
3.2.1
Zero-Order
captured
distribution.
Intuitively
rea-
sonable
Clustering
dimensional
birch
shape
Latent
qqqq
…
Good
(l1):
“clustering
algorithm”
body
Bad
(l2):
“body
shape”
p(w|qqqq)
)
|
Illustration
zero-order
circle
probability.
possibility
u0u1...um
(ui
word)
Score
p(l|θ)
p(l)
0≤i≤m
p(ui|θ)
p(ui)
independence
u′
assumed.
Basically,
“important”
(high
p(w|θ))
bias
toward
favoring
estimated
background
B,
sim-
ply
uniform.
essentially
likelihood
“generated”
opposed
492
say
“zero-order
vance”
considered.
en-
tire
utilized.
consist
“tree”
“apple”
“apple
tree”.
deeper
3.2.2
First-order
interpreted
context.
“rule”,
“association”,
“correlated”,
“frequency”
mining.
“decode”
conveyed
context,
covered
natu-
ral
extracted.
mismatch
representation
decide
ing.
let
{p(w|l)}
decided
l.
closeness
{p(w|θ)}
Kullback-
Leibler(KL)
D(θ||l).
KL
diver-
gence
perfectly
match
dimension
partition
hash
Context:
SIGMOD
Proceedings
P(w|qqqq)
P(w|l1)
D(qqqq|l1)
D(qqqq|l2)
7
Diagnostic
HUI
FANG,
Delaware
TAO
TAO,
Corporation
CHENGXIANG
ZHAI,
Developing
effective
long-standing
central
develop
necessary
deﬁciencies
current
trieval
relative
strengths
them.
analytically
experimentally
diagnose
weaknesses
provides
guidance
performance.
observation
closely
heuristics.
connect
implementations
heuristics,
strategies
check
implements
desired
strategy
heuristics
constraints,
constraint
implementation
relevance-preserving
turbations
diagnostic
tests
empirically
problems
ﬁx
[Information
Storage
Retrieval—Retrieval
Algorithms,
Experimentation,
Measurement
Additional
Key
Words
Phrases:
formal
TF-IDF
Reference
Format:
Fang,
H.,
Tao,
T.,
Zhai,
C.
Trans.
Inf.
Syst.
29,
Article
(April
2011),
42
pages.
DOI
10.1145/1961209.1961210
http://doi.acm.org/10.1145/1961209.1961210
[Salton
1975;
Salton
1983;
1989;
Singhal
1996a],
Part
material
appeared
Annual
SIGIR
Devel-
opment
2004.
article
upon
National
Foundation
grants
IIS-0347933
IIS-
0713581,
Alfred
P.
Sloan
Fellowship.
Authors’
addresses:
H.
Electrical
Engineering,
Delaware,
Newark,
DE
19716;
email:
hfang@ece.udel.edu;
T.
Corporation,
Redmond,
WA
98052;
taotao@microsoft.com;
Urbana-
Champaign,
Urbana,
IL
61801;
czhai@cs.uiuc.edu.
initial
screen
display
along
citation.
Copyrights
owned
others
honored.
Abstracting
credit
mitted.
servers,
component
requested
Publications
Dept.,
ACM,
Inc.,
Penn
Plaza,
Suite
701,
New
York,
NY
10121-0701,
USA,
fax
+1
(212)
869-0481,
permissions@acm.org.
1046-8188/2011/04-ART7
$10.00
Transactions
Systems,
Vol.
No.
Publication
date:
7:2
Fang
[Amati
2002;
Fuhr
1992;
Lafferty
2003;
Ponte
Croft
Robertson
Sparck
Jones
1976;
Turtle
Rijbergen
1977],
logic-based
[Fuhr
2001;
1986;
Wong
Yao
1995].
Despite
development
outperform
consistently,
seeking
remains
decade
Okapi
(BM25)
[Robertson
Walker
1994;
1995],
ﬁnd
consistently
robust
Okapi.
collections
evalu-
ation
(MAP)
10
utility
Unfortunately,
eval-
uation
explanation
differences
comparing
know
overall
dataset,
causes
differ-
ence.
optimized,
though
forms
differ.
suggests
(potentially
different)
strengths.
fur-
ther
weaknesses,
ideally,
pinpoint
hinder
accordingly
[Singhal
1996a,
1998].
sign
help
modiﬁed
motivation
comes
length
normalization.
Virtually
formulas
boil
down
explicit
implicit
implementa-
differently
(see,
e.g.,
experiment
TREC1).
appears
somehow
achieving
differently,
heuristic
worse
others.
monotonic
transformation
component,
normalizations
TF,
substantially
inferior
Buckley
1988;
Zobel
thus,
heuristic,
analytical
constraints
what
1http://trec.nist.gov/
7:3
satisfy
constraints.
formulas,
respectively
(pivoted
normalization
1996a]),
(Okapi
1994]),
(Dirichlet
[Zhai
2001a]),
randomness
(PL2
2002]).
straints
unconditionally,
violate
“seriously”
satisﬁed,
indicates
nonoptimality
satisﬁed
values,
tends
poor
range.
formula
tightly
sat-
isﬁes
observations
analytically,
analysis.
satisfy,
inevitably
limited.
alone
helpful
limitation
limitation,
weak-
nesses
experimentally.
amplify
perturbation
operators
tools
Such
perturbations
“extreme
conditions”
datasets
handling
extreme
conditions,
mon
designing
operators.
Following
procedure,
diag-
nostic
aspects
robustness
lengths,
resistance
noisy
balance
demonstrate
beneﬁts
diagnosis
methodol-
ogy.
reveal
clear
revealed
regular
Cranﬁeld-style
Second,
case
analysis,
helps
implementing
modify
achieve
Based
variants
isting
eight
shows
indicating
viding
improving
seven
7:4
discuss
Related
conclude
directions
FORMAL
CONSTRAINTS
ON
RETRIEVAL
FUNCTIONS
intuitive
satisfy.
way,
making
analytically.
characteristics
formulas.
“bag
words”
terms”)
involves
TF
part,
IDF
[Hiemstra
2000;
1996a;
intends
occurrences
term,
penalize
popular
avoid
chances
simply
contain
differ
combining
factors,
performances
similar.
“basic
requirements”
follow.
violates
“IDF
requirement,”
“unreasonable.”
requirements
compromise
normal-
ization
cause
receive
lower
TF.
Similarly,
pre-
cisely
single,
different,
allow
“beat”
critical
regulate
interactions
“playing
fair
game.”
question,
“fair
game,”
goal,
characterize
listing
necessary,
sufﬁcient,
want
satisfy;
indeed,
possi-
come
sense.
focus
notations.
t
term.
c(t,
D.
|D|
Sdenotes
S(Q,
Q.
td(t)
(usually
popularity
collection).
7:5
Inverse
t.
Term
Constraints
(TFCs)
contribution
scoring.
TFC1.
{q}
q.
|D1|
|D2|.
c(q,
D1)
D2),
D2).
TFC2.
|D2|
|D3|
D2)
D3)
TFC3.
q1,
q2
td(q1)
td(q2),
c(q1,
c(q2,
̸=
0,c(q2,
increase
partial
deriv-
ative
positive).
ensures
TFs
derivative
negative).
intuition
caused
increasing
100
101.
third
implies
property:
crimination
distinct
Discrimination
Constraint
(TDC)
TDC.
q2}
D1
D2,
|D2|,
q1
D2
q2.
td(q2)
∪
M-TDC
(modiﬁed
TDC)
Shi
[2005].
TFC2
TDC,
derived.
Q,
D,
D),
{q1})
{q2}).
relaxed
TDC
[2004],
might
overfavor
constraint,
“SVM
tutorial,”
99
“tutorial”
50
tutorial”,
somewhat
counterintuitive.
7:6
2.3.
Length
Normalization
(LNCs)
quantify
penalty
LNC1.
D1,
/∈
w,
c(w,
D1),
LNC2.
∀k
decrease
add
extra
“nonrelevant
word”
query).
overpenalizing
concatenate
times
redundant
2.4.
TF-LENGTH
(TF-LNC)
TF-LNC.
regulates
interaction
length.
sures
adding
D2.
TF-LNC
LNC1,
constraint:
D3
see
why,
|D2|+c(q,
D1)−c(q,
D1).
obvious
nonquery
According
TF-LNC,
longer
TFCs
intended
preferences
lengths.
I
intuitions
behind
formalized
constraint.
TFC1
LNC1
All
nonredundant
Formally,
{C1,
Cn}
Si
Ci.
Ci
redundant,
Si\S
j\Si
nonempty,
|Si\S
j|
|S
j\Si|
emphasize
once
again
section
formula,
7:7
I.
Summary
Intuitions
Formalized
favor
repeatedly
added
TFC3
document(assuming
TF)
LNC2,
over-penalizing
isfy.
When
violated,
empirically,
guarantee
CONSTRAINT
ANALYSIS
REPRESENTATIVE
previous
which,
respectively,
2001]),
prob-
abilistic
1995]),
smoothing
He
Ounis
2005]).
shown,
turns
hypotheses
regarding
formu-
las.
importantly,
formula.
notations
section:
Q)
N
df(t)
avdl
|Q|
C)
p(t|C)
2001a].
7:8
II.
Results
(Pivoted)
cmp-lg/9701001
Jan
1997
Exploiting
Context
Identify
Lexical
Atoms
--
View
Linguistic
Laboratory
Computational
Linguistics
15213
U
Email:
cz25@andrew.cmu.edu
Abstract
Interpretation
inherently
context-sensitive.
Most
ambiguous
meanings
dependent
used.
lexical
separated
notion
atoms,
“sticky”
“hot
dog”.
atoms
occur
unrestricted
text,
recognizing
understanding
naturally-occurring
proposes
exploiting
communication
relies
situation
performed.
surprise
interpretation
situations
sentence
differently;
anaphors
resolved
structural
ambiguity
importance
understanding,
studied
linguists[Allen
95,
Alshawi
87].
emphasized[Cruse
86,
Rieger
91,
Slator
Schutze
92].
ambiguous,
contexts.
“bank”
institution
looks
your
money
(the
“money”
sense)
river
“river”
sense).
look
“bank”.
Sometimes
(such
“high
interest
bank”)
sufficient
disambiguation;
needed,
(E.g.,
“He
went
bank
yesterday”,
insufficient
disambiguation
richer
needed.)
clues
Firth
said,
“You
shall
company
keeps”
[Firth
57].
“money”,
“account”,
“interest”
occurs
sense;
“river”,
“water”
special
kind
units
atoms.
atom
dog”,
constituent
carry
meanings.
multi-word
processed
compositionally,
exploit
Acquisition
lexicon
acquisition
linguists
[Zampolli
al
Saint-Dizier
Zernik
91].
fact
grammar
theories
converging
role
theory.
availability
large-
scale-up
practical
developing
lexicon:
construction
acquisition.
time-consuming
labor-intensive,
acquiring
attractive
[Zernik
multiple-word
non-compositional
meaning,
direct
composition
literal
comprise
almost
“hot”
“dog”.
Proper
“Hong
Kong”,
“artificial
intelligence”).
constantly
invent
“TV
dinner”).
Because
non-compositional,
naturally,
unit,
rather
composite
structure.
Lexicographists
entries[Hartmann
83].
recognize
indexing[Evans
96].
translation,
needs
translated
[Meyer
90].
compositionality
linguists[See
Dowty
81,
Pustejovsky
92,
Pereira
89,
Pollack
90,
Dale
89
others].
difficulty
“White
House”
government
report,
report
“a
big
white
house”).
generative
[Pustekpvslu
95]
[Cruse
Evens
88].
item
defined
notions
conceptual
primitives).
intensional
extensional
content
described;
items.
relation
dependency
items
described.
acquisition,
exploits
dictionaries
extracts
entry
definition;
corpora
collocations.
nature,
regard
“defined”
atom.
characteristic
non-
compositionality,
combination
normal
keeps
meaning.
define
two-word
definition
Atom:
noun
[X
Y]
atom,
instance,
“natural
gas”
(as
gas
company)
judged
“natural”
“gas”.
“gas”
seems
here,
all,
“natural”.
“stock
market”
“stock”
“market”
contributing
market”.
context-dependent,
phrase's
context-dependent.
“white
house”
given,
compositional
uncertain,
clear-cut.
“bottom
line”
judge
uncertainty
context-sensitive
levels
Theoretically,
extremely
deep
detailed
domains,
parse
hard.
reason,
simplified
corpus-based
linguistics
processing.
disambiguation,
fixed
window
context)
center
[Schutze
Gale
identification,
follow
simplification.
Specifically,
restrict
word/phrase
surrounding
50-word,
10-sentence
window).
This,
course,
excluding
pragmatic
environment
users),
syntactic
relation,
Nevertheless,
simplification
easier
information,
compositionality:
Phrase-Word
Cooccurrence
(PWC)
proportional
X's
Y's)
occurring
Y].
radically
unlikely
expect
“dog”
dog”
Word
Association
(WA)
association
then,
away
association.
associations
contexts
Similarity
(CS)
different.
“dog”,
share
“market”.
statistics.
measures.
word/phrase.
[X,Y]
Y;
FQ(X)
FQ(X:Y)
N-word
window.
PWC
[u,v]
u
v
respectively)
FQ(u:[u,v])
PWC([u,v],u)=

FQ([u,v])
FQ(v:[u,v])
PWC([u,v],v)=
FQ(u:v)
-
WA([u,v])=

CS
[u,v],
first
word.
forming
92],
disambiguation.
following:
collect
w).
characterizes
w.
determined
counting
considering
idf-tf
scoring,
inversely
"FQ(c:w)/log(FQ(c)+1)".
numbers,
vectors.
v1=(x1,x2,...xn)
v2=(y1,y2,...,yn),
cosine
v1
v2
x1*y1
x2*y2
+...
xn*yn
sim(v1,v2)=

sqrt(x1*x1+...+xn*xn)*sqrt(y1*y1+...+yn*yn)
get
measures,
CS,
Once
identified
selecting,
below
implemented
20-megabyte
chunk
Associate
Press
Newswire
(from
Tipster
Collection
[Harman
95]).
tagged
lexicon.
functional
dropped
condensed
substantial
(mainly
nouns,
verbs,
adjectives)1.
400
frequent
noun-noun
11-700)
candidates
unless
specified,
size
80,
preceding
40
“context”
collocations,
finding
collocations
compositionality.
[See
Smadja
Church
Dunning
93].
Mutual
(MI).
Informally,
MI
compares
observing
pair)
independently.
greater
adjacently
chance.
Details
[Church
89]
bottom
indeed
not,
extent.
asylum
seeker
affirmative
action
blue
chip
pork
belly
black
tie
Savannah
River
square
root
Italian
lira
death
drug
czar
enforcement
official
feeder
cattle
en
route
red
cross
Holly
Farm
guest
house
Swiss
franc
French
Warsaw
Pact
Jimmy
Carter
Naturalization
Service
counsel
jumbo
jet
operation
rescue
wind
chill
surgeon
around
14
megabytes.
seemed
school
student
police
income
tax
reagan
budget
pacific
coast
state
dollar
tender
african
African
time
Chinese
aids
virus
year
152
difficult
well-defined
judgment,
description
pair's
involve
it.
“Japanese
student”
“student”
who
“Japanese”,
nor
But
“real
estate”
“estate”
“real”.
vague
cases
imagine
great
inconsistency
judgments,
precisions
points,
corresponds
pre-specified
cutoff
pairs,
8
0.8
10).
(over
atoms)
curves.
0.900
0.800
0.500
0.700
20
0.850
0.600
30
0.833
0.875
0.825
0.625
0.820
0.740
0.757
0.729
0.586
0.771
0.710
0.540
0.680
150
0.633
0.647
0.613
200
0.535
0.580
0.485
0.565
300
0.470
0.467
0.420
0.457
0.380
0.681
0.678
0.515
0.655
Precisions
Illllllllll
I!
I:=!
I~
Ill
{=
!1
~
F
E
R
!t
G
TWO
Sides
Same
Coin?
Nicholas
J.
Belkin
W.
Bruce
filtering
processes
delivery
articles
describing
electronic
mail,
multimedia
office
routing,
dear.
distinction,
specific
addressed.
defining
mentioned:
unstructured
semistructured
contrasts
structured
employee
records.
here
conforms
format
record
description,
fields
records
journal
figure
¢ONNUNle.INI,
TIQNI
Opllllil~-IMl/Decem}~er
1992/Vo|.35,
No.12
type,
salary.
Email
messages
header
body.
deal
textual
synonym
images,
voice,
video
informa-
None
handled
conven-
tional
repre-
sent.
Filtering
amounts
Typical
gigabytes
media.
volve
streams
incoming
ei-
broadcast
remote
sources
services),
sent
(email).
process
retrieving
databases,
searches.
scenario
developers
tems
"intelligent
agents"
searching
remote,
heter-
ogeneous
databases.
descriptions
preferences,
profiles.
profiles
long-term
interests.
meant
imply
removal
incom-
stream,
stream.
users
removed;
lat-
ter
tracted.
email
filter
signed
'~junk"
mail.
express
want,
want.
well-
Iliiillllll
closer
examination,
virtually
text-based
tems.
volves
sending
individuals
groups.
fil-
tering.
Categorization
[11]
attach
predefined
(this
ser-
vices,
example).
dif-
ference
static
Extrac-
[27]
ferent
traction
facts
determi-
nation
secondary
issue.
[22]
filtering.
Selective
Dissemination
(SDI)
[14],
identi-
plications.
processes,
is-
sues
involved,
tailed
comparison.
comparison,
subject
past
years
field.
filtering,
issues.
clarifying
similarities
ences
benefit
Concepts
(IR)
characterized
ways,
ranging
goals,
abstract
processes.
Al-
characteriza-
agreement
another,
commonalities.
"leading
enable
him/
her
his/her
mation"
[17].
Somewhat
"the
[re-
trieval]
edge
resource
her/him
management"
[1].
indi-
cates
entities
situation.
person
goals
intentions
task,
finds
attained
person's
resources
knowledge
inadequate.
characteris-
"problematic
situation"
[23]
anomalous
(ASK)
[2]
need,
prompts
engage
tive
information-seeking
behavior,
submitting
expressed
understood
need.
right-hand
Due
inherent
rep-
resenting
ASKs
[2],
proximate
imperfect.
eventually
access.
considers
producers
thors
texts*;
groupings
databases);
texts;
and,
organi-
zation
representations
databases
surrogates.
cess
amenable
(sometimes
indexing)
impor-
tance
index
keywords.
sur-
rogates,
or,
teraction
*We
1992/Vol.35,
/¢OMIJUNICATION|
OFTHE
surrogates
hypertext
systems),
leads
possibly
retrieved
texts.
leave
modification
rarely,
feedback
[22].
inter-
est.
been,
genera-
texts,
producers,
solely
op-
erational
experimental
concentrated
cesses
ganization,
modification.
performance,
line
emphasized
stud-
ies
involved
tems,
investigated
queries;
sentation
states
un-
derlying
interactive
particular,
intermediaries;
user's
goals;
interac-
scription
tures,
filter-
presented
begins
system)
stable,
long-term,
periodic
desires
accomplishing
entertained).
Groups,
individuals,
goals.
interests
keeping
up-
to-date
topic)
slowly
change.
mliinNiNiNi
3DmD
mqom
in:
Person
Goals,
Tasks,
Producers
Texts
/
Intentions,
Etc.
Collections
Need
(Databases)
Anomalous
State
Knowledge
Representation
Organization
Surrogates,
Organized
Comparison
Interaction
Retrieved
Use
Modification
Users
Groups
Periodic
Long-Term
Distributors
Regular
Interests
Distribution
Surrogates
Profiles
Pigure
COHHUNICA?IONIOP'IPII41
tar.M/December
3~
passive
brought
at-
tention.
accomplished
resentation
ests
put
files
construed
specifications
institutions,
newspa-
pers,
individuals.
others,
newsgroups,
undertake
distribute
generated,
users'
atten-
accomplish
this,
files.
(being
retrieved).
not)
respond
motivating
modified
subsequent
discussing
Fig-
ures
note
level
tering
be:
Where
one-time
one-
repeated
persons
recognizes
adequacy
needs,
organization
individu-
als.
atively
database,
Ol
WI:2
DI21CI
H
elimination
dynamic
datastream.
sponding
tion-seeking
episode,
cerned
changes
epi-
sodes.
distinctions
ing,
seem
arise
social
concerned.
categorized
users,
concern
each.
Text-related
timeliness
overriding
significance.
case.
User-related
by-
and-large,
groups,
well-defined,
largely
tech-
nology.
behaviors.
Fil-
tering,
undefined
communi-
ties,
enter-
tainment
homes,
varied
domains.
Also,
motiva-
can-
Environmental
salient
concerned,
rmation
Concepts,
ieval,
Services
North
Carolina,
Chapel
Hill
ion
edited
Gary
Marchionini
na.
publish
50-
100-page
publications
ce
technology
discovery,
production,
scope
purview
premier
uch
ASIST,
SIGIR,
ACM/IEEE
JCDL,
CIKM.
to:
indexing
tecture,
economics,
privacy
identity,
scholarly
nd
webometrics,
management,
braries,
archives
preservation,
cultural
informatics,
feedback,
recommendation
multilingual
h.
M)
Processes
Organizations:
Theoretical
Foundations
E.
Koenig
Conﬂuence
Database
Technologies
Wilber
Books
Cyberspace
Identities
-Oriented
System
hien-Yi
Hou,
Christopher
A.
Lee,
Richard
Marciano,
Antoine
de
eder,
Sheau-Yen
Chen,
Lucas
Gilbert,
Paul
Tooby,
Bing
Zhu
o,
What,
Where,
When,
Why
val
Design
Integration
Spaces
onic
Book
onary
Perspective
Models,
Architectures
ico
actions
Web
Analytics
Quantitative
Social
ltimedia
Systems:
Creation,
Reﬁnement,
ypool
blication
reproduced,
stored
transmitted
mechanical,
photocopy,
recording,
brief
quotations
ission
publisher.
rback
01105ICR019
laypool
Publishers
FORMATION
CONCEPTS,
RETRIEVAL,
AND
SERVICES
7-9468
Technology
INFORMATION
cLaypool
publishers
g
unity
fortunate
well-grounded
riod
oal
explaining
methodologies
came
dapt
vastly
changed
engine
world
scussion
1960s,
continuing
Lancaster
“user”
investigations
project
er
why
devel-
he
“batch”
examining
campaigns
TREC,
NTCIR
(emphasis
Asian
lan-
opean
languages),
INEX
semi-structured
data),
evolving
older
ormation
metrics
operational
environ-
valuation
studies–the
earch
engines.
tudies,
high-level
affect
Cranﬁeld
paradigm,
TREC
rly
History
.1
RS
9
ystem
ve
Systems
Case
Western
“Ideal”
22
1992
25
27
luations
(1992-1999)
EC
34
etrieval
“noisy”
36
non-English
37
ge
enterprise
38
-speciﬁc
39
limits
46
47
48
51
using,
building
52
55
57
62
ractive
66
82
87
107
ne
person,
am
grateful
writers
before
me
detail
careful
documentation
discussions
members
community
ated
evaluation.The
Group
NIST
(especially
Ian
Soboroff
ckley
patiently
listened
told
wrong,
getting
details
lecture.
Emily
Morse
hapter
assured
properly
documented
area
Stephen
helped
gather
Library
got
scan
public
consumption.
der
reports,
plus
Doug
Oard
borrow
needed.
preliminary
reviewer
his
comments.
ial
thanks
Ellen
Voorhees,
discussions,
eview
Chapter
sure
did
right
recorded.
rateful
reviewers
entire
lecture,
Mark
Smucker
John
ny
highlighted
areas
took
read
comments,
ortant
Early
ION
reasons,
buy,
user-friendliness
bout
measure-
doing
nderstand
happening
inside
emphasis
re
sured,
recognized.
ses
starting
ly
MEDLARS,
st
s
chapter
effectiveness,
discussion
metrics,
readers
ns
elsewhere.
noted
references
online.
Readers
interested
history
vers
methodolo-
European
handle
diﬁed
o
advice
build
review
studies,
ediaries,
experiences
e
ﬁnal
ommercial
show,
xperimental
TESTS
ed
Cyril
Cleverdon)
cited
“standard”
from,
Cleverdon’s
account
eech
1991
award
[53].)
parate
Cleverdon,
Librarian
College
staff.
ﬁrst,
running
1958
1962
(classiﬁcation)
existed
time–text
uld
“word-of-mouth”
specialist
librarians,
massive
indexes
ubject
Index,
Engineering
Index.
rease
volume
papers
World
War
II
ese
keep
current.
expensive
ntention
use.
edito-
competing
essential
rating
age
old
controversies
arose
concepts
mechanized
future.”
encouragement,
presenting
Detroit
proposal
ded
started
1958.
summarized
considered,
indexer’s
em,
searched.
ch
cost
prepare
locate
required
irrelevant
orts
ﬁeld
aerodynamics
(obviously
ng
alphabetical
catalogue,
faceted
Decimal
Uniterm
co-ordinate
nant
vogue.
experience
matter.
Experience
rotation
throughout
control).
ﬁnish
ifﬁculties
encountered
indexer
fatigue).
working
ions
searching).
test,
1953,
never
[76].
h
15,000
About
earched
team
index.The
end
teams
ir
results!
oid
trap,
wanted
stimated
1,600
ur
indexes.This
impossible
nown-item
searching,
(which
guaranteed
mirror
setting,
18,000
Cleverdon
sking
authors
satisfactorily
answered
document”.
uestions,
subsetted
batches
heck,
batch
panel
discarded).
equired
documents,record-
ccess
failure)
search.The
results–the
failed
gniﬁcant
failures
error”,
indexers.
med
inconclusive
surface,
discover
huge
failure
descriptors
Were
ore
(exhaustive
(generally),
(called
“relevance”
1964).
actic
relationships
indexing,
erdon
continue
(1962-1966)
Jean
Aitchinson
Reserve
[3]
testing.The
creation
ork
avoiding
judging
(and
eas
deciding
1200
felt
(documents,
ts),
searching.
ully
collection.The
urally
ask,
ocument
questions,
document.The
962
speed
eir
authors,
tructions
authors.
ading
paper,and
supplemental
ourse
were,
references,
estions
given.The
assessment
complete
egree
resulted
work.
suggesting
rtain
interest,
included
ms
returned,
3.5
form.
173
(those
ted
correctness
minimal
graduate
students
spent
summer
1963
gments
361
against
1400
decision,
graded
sly.
Judgments
returned
279
21
(compound
built
experimentation
begin.
amine
depth
properties
methodologies.
33
set).The
owever,
variables
searchers
coded
cards
“Beehive”.
ould
device
co-ordination
Boolean
“anding”
during
basis.
“run
1”
experiment,
investigated,
“anded”,
riterion
retrieved.
un
2”
hing.
phasize
searching;
ms,simple
concepts,and
terms.On
alled
devices,
(stemmed)
forms,
ierarchies
thesaurus.
devices
o-ordination
rst
concept
level,
“terms
isolation
handles
context;
etc.”.
ment:
9/10
theme
7/8
5/6
minor
subsidiary
I-3
I-2
I-1
I-6
I-8
I-7
I-5
II-11
II-10
III-1
III-2
I-9
IV-3
IV-4
III-3
IV-2
III-4
III-5
III-6
IV-1
II-15
II-9
II-13
II-8
II-12
II-5
II-7
II-3
II-14
II-4
II-6
II-2
II-1
Synonyms
Synonyms,
quasi-synonyms
Hierarchy
Synonyms.
Quasy-synonyms
Simple
concepts.
Hierarchical
Alphabetical
Controlled
Basic
Narrower
Abstracts.
Broader
Titles.
broader
Narrower,
Complete
species
superordinate
Somple
Selected
coordinate
collateral
Superordinate
ER
EFFECTIVENESS
BASED
NORMALISED
ALL
FOR
CRANFIELD
INDEX
LANGUAGES
ERAGE
NUMBERS)
dexing
postings
31.3
25.2
7/10
12.9
els
exhaustivity
indexing.
ut
contrast,and
exhaustivity,
lus
“automatically”
indexed.
declared
ained
abstracts/titles
ccurrences
gave
titles.
centering
“Recall
Ratio”
b).
Perry
[128]
Recall
tor,
Other
ratio
ratio,
pertinency
[147]
metrics).
liked
cision
suggested
Bourne,
Farradane,
221
ratios
experiment.
earlier,
point,
co-ordinating
%
40%
12%
precision.These
plotted
recall/precision
curve
looking
questions.
ually
worked
grand
ﬁgures
divide
today
simplest
(remember
aware
method;
that,
wed
cro-averaging).
do;
aerodynamics,
nts
(but
questions).
eriments
compared;
relevant/non-relevant
tion,was
c)/(a
used,along
ability
non-relevant
experiments?
copied
8.1T
“index
languages”.
[51]
details)
coming
1.4).
languages
esults
(stems)
[51].
seemingly
inexplicable
conclusion
guages
superior
type.
....This
hat
throw
doubt
ults,
reaction
evidence.
screpancies,
distorted,
course
offend
canon
furor
arguments
171].
mostly
centered
questions)
deﬁnitions
relevancy.
Whereas
ejection
conclusions,
digm
(although
consensus
antoutcomesfromCranﬁeld2fortheﬁeldofinformationretrieval.
alteration
concepts),
ove
outcome
paradigm
Today
metrics.
subtle
compo-
on.The
ection
“users”
(via
pieces
strict
separation
earlier
ave
forgotten
today,
light
nﬁeld
paradigm.
place
1966
Medical
Literature
System)
[115].By
Investigating
models:
PLSA
LDA
Yue
Lu
Mei
ChengXiang
Received:
November
2009
Accepted:
2010
Published
online:
Springer
Science+Business
Media,
LLC
Probabilistic
successful
clustering.
promising
systematically
unanswered,
maxima
conducting
systematic
investigation
(PLSA)
Dirichlet
Allocation
(LDA),
clustering,
ad-hoc
standing
optimize
task-based
framework
general-
izable
family
LDA.
Keywords
Experimentation
(&amp;)
Urbana-Champaign,
201
Goodwin
Ave,
61801,
e-mail:
yuelu2@illinois.edu
czhai@cs.uiuc.edu
Information,
Michigan,
1085
South
Ann
Arbor,
48109,
qmei@umich.edu
123
Inf
(2011)
14:178–203
10.1007/s10791-010-9141-9
Recently,
(Hofmann
1999a;
Blei
2003,
2004,
2005;
Wang
McCallum
2006,
Nallapati
2008).
While
sample
mixture
model).
potentially
inferring
Maximum
Likelihood
estimator
(e.g,.
Hofmann
1999a),
inferences
2003)
themes)
Discovered
demonstrated
Grifﬁths
Steyvers
2004;
2007;
Wei
2006;
Cai
utilization
Discovering
(e.g.
2007)):
revealing
text).
Obtaining
low-dimensional
1999b;
2008):
serve
word-based
supporting
Expanding
accommodate
Yi
Allan
2009).
expanded
recover
‘‘smoothed’’
word-level
matching.
success
gap
remain
unanswered:
families
1999b)
(LDA)
(Blei
perplexity
held-out
Wallach
2009),
generalization
modeling.
The-
oretical
reveals
(Girolami
Kaba´n
2003),
indicate
179
perspective,
advantages
2003).
numerical
inferences.
maxima,
presumably
maximum.
investigating
inﬂuence
theoretically
suffer
maxima;
tasks?
Third,
estimation
iterative
iterations
non-optimal
estimation,
sub-optimal
(due
iterations)
formance?
Is
aspect?
pre-specify
performance?
hyper-parameter
LDA)
arbitrarily
justiﬁcation
(Wei
answers
guide
optimizing
quantitative
requiring
ﬁne
granularity
generalizable
data;
similarly.
setting
hyper-parameter,
hyper-parameters
varies
task;
affects
PLSA),
promotes
matching,
discrimination;
high-dimensional
effective.
ﬁndings
Sect.
introduction
After
Sects.
180
Previous
(1999a)
introduced
1999,
impressive
1999b),
parameterization
susceptible
overﬁtting
straightforward
seen
al.,
limitations
proposing
Later,
extensions
proposed.
(2004)
showed
Gibbs
sampling,
Markov
chain
Monte
Carlo
technique,
experimented
Academy
Sciences.
(2004),
extended
support
extends
authorship
Mccallum
(2006)
capturing
correlations
directed
acyclic
graph
(DAG).
extension
incorporate
regularize
harmonic
(Mei
(2005),
(2006),
(2008),
esting
scenarios.
successfully
mine
sum-
marize
(Grifﬁths
2007).
Promising
Lacoste-
Julien
(2008)
specialized
classiﬁ-
cation
framework.
(2009)
in-depth
PAM,
dependencies,
demonstrates
clustering
LapPLSI.
studying
connection
comprehensive
made,
algorithms.
2005,
answered.
(Chang
2009)
conducts
inferred
interpretability
effort,
quantiﬁed
objectively
supplementary
theirs.
181
Non-negative
Matrix
Factorization
(NMF)
family.
Gaussier
Goutte
solves
NMF
divergence.
algebra,
interpretations.
intent
ones,
i.e.
1999a)
mixtures
documents:
speciﬁes
generated.
writing
chooses
Then,
draws
Different
assumptions
made.
Notations
ﬁnite
K
z
P(w|z)
V.
P(z|d)
z.
simplify
notations,
/ðjÞ
¼
Pðwjz
jÞ
refer
hðdÞ
Pðz
jjdÞ
d.
1999a,
Hoffman.
PðwjdÞ
j¼1
ð1Þ
Estimation
word-topic
^/
topic-document
^h
Expectation-Maximization
(EM)
(Dempster
1977)
(log)
model:
PðDj/;
hÞ
d2D
w2V
cðw;
dÞ
ð2Þ
E-step,
hidden
iteration:
Pðzd;w
PK
j0¼1
/ðj0Þ
j0
ð3Þ
M-step,
updating
P
dÞPðzd;w
j0Þ
w02V
d2C
cðw0;
dÞPðzd;w0
3.3
well-deﬁned
2003);
unseen
grows
linearly
overﬁtting.
(LDA).
resembles
PLSA.
conditioned
conjugate
prior.
multinomial,
convenient
prior,
inference.
speciﬁed
a1,...,
aK.
aj
sampled
mathe-
matically
symmetric
hyper-
a1
a2
_
aK
a.
density
by:
PðhðdÞjaÞ
DirðhðdÞjaÞ
CðKaÞ
CðaÞK
ðhðdÞ
Þa�1
ð4Þ
CðxÞ
tx�1e�tdt
factorial
argument
shifted
numbers.
equation
factors
placing
h,
smoothed
parameter.
hyper
placed
b,
inte-
grating
/:
183
PðDja;bÞ
Z
/ð1Þ
���
/ðKÞ
i¼1
Pð/ðiÞjbÞ
!cðw;dÞ
dhðdÞd/ð1Þ
d/ðKÞ
approximate
inference
variational
expectation
propagation
(Minka
2004),
sampling
(Geman
Geman
1984;
2004).
(Teh
Go¨ru¨r
perplexity,
hyperpa-
rameters
diminish
sig-
niﬁcantly.
optimum
prevalent
2006)
Never-
theless,
fw1;
w2;
.;
wNg,
token
wi
di
turn,
samples
zi
wi:
tokens
z-i.
Pðzi
jjz�i;
wÞ
nðwiÞ
�i;j
þ
nð:Þ
Nb
nðdiÞ
�i
Ka
ð5Þ
j,
word;
one;
From
wÞ,
token.
done,
^/ðwÞ
nðwÞ
ð6Þ
^hðdÞ
nðdÞ
ð7Þ
j.
184
j;
forcing
moving
corners
simplex,
(Steyvers
\
modes
located
simplex.
sparsity,
pressure
pick
recommended
2007)
50/K
0.01.
(Zhai
2008;
3.4
Un-answered
(2003)
outperforms
predicting
Girolami
proves
equivalent
uniform
tematic
emperical
optimally
similarly?
extent
models?
Existing
providing
low-
representation.
improvement?
Can
representation?
cannot?
EM
maximum;
reach
stability
sampling.
regularizing
practice?
185
sections,
(PLSA
sentative
acknowledge
numerous
distraction
focus,
intentionally
Rather,
start
baseline;
commonalities
differences,
Generally,
map
(word
features)
Trends
⃝
Nos.
1–2
1–224
Kelly
10.1561/1500000012
Methods
Evaluating
Interactive
Diane
Contents
Purpose
Scope
Sources
Recommended
Readings
6
Outline
Retrieval?
Background
15
Cognitive
Viewpoint
17
4.1
Exploratory,
Descriptive
Explanatory
Studies
4.2
Evaluations
4.3
Naturalistic
4.4
Longitudinal
28
4.5
29
4.6
Wizard
Oz
Simulations
Basics
31
5.1
Problems
Questions
5.2
Theory
5.3
Hypotheses
5.4
Variables
35
5.5
Considerations
5.6
Levels
41
44
6.1
Traditional
Designs
IIR
6.2
Factorial
6.3
Between-
Within-Subjects
49
6.4
Rotation
Counterbalancing
6.5
Randomization
User
Choice
56
6.6
Study
Mode
6.7
Protocols
58
6.8
Tutorials
6.9
Timing
Fatigue
59
6.10
Pilot
60
Sampling
61
7.1
Probability
63
7.2
Non-Probability
Techniques
7.3
Recruitment
68
7.4
Users,
Subjects,
Participants
Assessors
69
8.1
Documents,
Topics,
Tasks
8.2
Needs:
Topics
84
9.1
Think-Aloud
9.2
Stimulated
85
9.3
Spontaneous
Prompted
Self-Report
86
9.4
Observation
9.5
Logging
9.6
Questionnaires
91
9.7
Interviews
95
9.8
End
Products
96
Measures
10.1
Contextual
103
10.2
105
10.3
106
10.4
Evaluative
Feedback
Subjects
116
126
11.1
Qualitative
11.2
129
12
Validity
Reliability
176
Ethics
13.1
Who
Subject?
13.2
Institutional
Review
Boards
13.3
Guiding
Ethical
Principles
13.4
Speciﬁc
Concerns
Researchers
188
Outstanding
Challenges
Future
Directions
193
14.1
Types
14.2
196
14.3
198
Conclusion
202
References
205
Carolina
Hill,
NC,
dianek@email.unc.edu
overview
instruction
primary
catalog
compile
source.
historical
back-
user-centered
systems;
tion;
designs
strate-
gies;
presents
core
instruments
measures;
(5)
techniques;
reviews
discusses
validity
reliability
ethics
ethical
(IIR).
concludes
outstanding
directions.
experienced
growth
numbers
end-users.
incorporation
users’
behaviors
concerns
[46].
prescribed
dominant
traced
back
[54],
well-established
determine
proceed
guidelines
missing.
(IIR),
clas-
sic
humans
physical,
cognitive
aﬀective
asks
retrieve
documents?
focused
informed
ﬁelds
traditional
library
psychology,
human–computer
(HCI).
HCI,
sub-area
Ruthven
[225]
argues
convincingly
area.
HCIR,
established
uniqueness
[191]).
proposition
fundamentally
perspective
new.
leaders
wrote
entitled
“Evaluation
lems
retrieval”
1970.
[229]
attitudes
perceptions
[55]
presentation
Tague
Schultz
[259]
friendliness.
feedback.
Looking
action,
diﬃculties
Assuming
enter
opportunities
consequences
head.
querying,
saving
activities.
observable
activity;
save
adds
needs.
User–system
inﬂuenced
measurable.
behavioral
disposition.
sorts
complete,
expectations
[139,
194].
Individual
same,
establish
causal
relationships.
measurement
practices.
IIR,
science.
unite
traditions
sciences
interfaces
scenarios
go
beyond
this.
exception
[34,
149]).
contrast
disciplines
few,
any,
programs
investigate
despite
[231].
Tague’s
[260,
262]
chapters
Sp¨arck-Jones
[246]
writings
15–20-years-old.
argued
Sp¨arck-Jones’
book
environments,
consult
textbook
solid
one’s
study.
foundation
subjects.1
laboratory
kind.
qualitative.
statement
importance,
maintain
prescribe
step-by-step
recipe
imprudent
cally,
iteratively,
time.
interdependent;
impacts
choices.
Understanding
possibilities
situations.
intellectual
Prescriptive
interchangeably
tinction
population
prevent
discovering
things.
methodological
considerations
Digital
libraries,
occurs,
cussed
explicitly,
again,
[29].
surveys
ducted
IIR.
survey
comprehensive.
illustrate
issues,
[225].
historic
spective,
Vickery
[23].
consulted
cre-
greatly
262,
263,
264]
seminal
pieces.
formed
devoted
individ-
ual
Borlund
[32,
34]
contributed
simulated
Haas
Kraft
[115]
reviewed
Ingwersen
J¨arvelin
[139]
seek-
[80]
participants
contributions
Sugar’s
[255]
perspectives
al.’s
[277]
Ruthven’s
version.
(ARIST)
pub-
lished
40-year
King’s
[173]
systems,2
Kantor’s
[161]
Rorvig’s
[223]
psychometric
Harter
Hert’s
[123]
Wang’s
[290]
journals
worth
mentioning.
[37]
IP&amp;M
Dunlop
[82]
Inter-
acting
Computers
Harman’s
[120]
IP&amp;M,
Hancock-Beaulieu’s
[221]
understandings
behavior.
Savage-Knepshield
Belkin’s
[240]
Saracevic’s
[233]
J¨arvelin’s
reading
evolution
instrumen-
tal
paper:
Babbie
[13],
[56],
Gravetter
Wallnau
[110],
Myers
Well
[200],
Pedhazur
Schmelkin
[208],
Williams
[296].
discus-
history.
brieﬂy.
Six
ARIST
title,
1968–1975.
basics
theory,
hypotheses,
ables.
advanced
skip
sam-
pling
(Section
7).
Instruments
8,
lengthy
11;
qualitative
provided,
starts
skim
parts
section.
Discussions
12.
14.
IIR?
really
tell
story.
think
middle
continuum
anchored
(Figure
2.1).
situated
spectrum
tracks
continuum.
se.
assessors
present,
place.
Voorhees
[288]
move
continuum,
april
2012
vol.
no.
communicationS
acm
Doi:10.1145/2133806.2133826
Surveying
suite
managing
archives.
DaviD
m.
OUr
COLLeCTive
continues
digitized
stored—in
news,
blogs,
pages,
scientific
books,
sound,
video,
networks—it
find
for.
organize,
vast
Right
now,
tools—search
links.
keywords
navigating
linked
powerful
interacting
archive,
something
Imagine
exploring
run
“zoom
in”
out”
themes;
connected
Rather
keyword
alone,
in,
York
Times.
newspaper—for-
eign
policy,
national
affairs,
sports.
zoom
terest,
foreign
it—Chinese
conflict
Middle
East,
U.S.’s
relationship
Russia.
navigate
changed,
tracking,
East
years.
And,
exploration,
pointed
themes.
thematic
digest
interact
elec-
tronic
online,
browsing
above.
end,
probabilis-
annotate
algo-
rithms
ana-
lyze
them,
pervade
organize
Recent
advances
field
analyze
streaming
collections,
you
aPi.
adapted
patterns
genetic
networks.
(See,
Yale
Law
Journal.)
annotations
documents—the
emerge
origi-
nal
enables
impos-
sible
annotation.
allocation
ideas
model.8
intu-
ition
exhibit
“Seeking
Life’s
Bare
(Genetic)
Necessities,”
genes
organism
survive
evolutionary
“computer”
“prediction,”
high-
lighted
blue;
biology,
“life”
“organism,”
pink;
genetics,
“sequenced”
“genes,”
yellow.
highlight
arti-
cle
blends
biology
portions.
(We
“and”
“but”
“if,”
topical
content.)
know-
situate
articles.
intuition.
process,
imaginary
arose.
(The
fleshed
later.)
vocabulary.
genetics
specified
generated.a
Technically,
top-
ics
first,
ate
two-stage
˲
Randomly
#1.
b.
reflects
mul-
tiple
exhib-
proportion
(step
#1);
#2b),
#2a).b
mysterious
name,
“latent
allocation.”
draw
#1
cartoon
histogram
allocate
latent?
Keep
reading.
allocation.
“topics,”
exist
(far
left).
right);
word,
colored
coins)
illustrative—they
fit
See
gene
dna
life
evolve
brain
neuron
nerve
Documents
proportions
0.04
0.01
ics.
Notice
neuroscience;
distinguishing
allocation—all
proportion.
introduc-
themselves
observed,
structure—the
per-word
assignments—is
thought
“reversing”
process—
collection?
infer-
ence
17,000
magazine
topics.)
left),
par-
ticular
“acti-
vated”
handful
Further,
probable
right).
recognizable
survival,
bined
jects
pretable
documents.c
Journal.
(Here
num-
ber
20.)
Indeed
calling
“topic
models”
retrospective—the
interpretable
interacts
subjects
replaced
contract
law.
stems
property
hid-
den
annotates
collection—a
painstaking
hand—and
aid
classification,
exploration.d
model-
managing,
organizing,
annotating
Lda
treat
arising
variables.
defines
See,
browser
http://www.sccs.
swarthmore.edu/users/08/ajb/tmve/wiki100k/
browse/topic-list.html.
Real
lDa.
100-topic
lDa
Science.
“Genetics”
genome
molecular
sequencing
sequences
“Evolution”
organisms
origin
phylogenetic
living
diversity
“Disease”
disease
host
bacteria
diseases
bacterial
strains
control
infectious
malaria
parasite
parasites
united
tuberculosis
“Computers”
computers
software
simulations
16
0.0
0.1
0.2
0.3
0.4
80
posterior
precisely
frame-
structure;
b1:K,
bk
dth
qd,
d,k
car-
toon
zd,
zd,n
nth
coin
wd,
wd,n
notation,
fol-
lowing
variables,
specifies
dependencies.
assign-
b1:K.
(Operationally,
topic.)
dependencies
encoded
mathemati-
and—
way—in
graphical
distributions.e
graphi-
pause
ideas.
fix
previ-
ously
(pLSI).21
Random
Walks
Adjacency
Graphs
Relations
Big
Shan
Jiang
IL,
sjiang18@illinois.edu
Abstract—Lexical
relations,
languages.
walks
adjacency
graphs
paradigmatic
syntagmatic
opens
patterns,
walk
min-
relations.
walk-
dramatic
creates
“big
data”
analytics
structured,
discovery
languages,
scalable
connects
distributionally
together;
statistically
as-
sociated
semiotics,
Paradigmatic
tells
playing
roles
rule,
synonym-like
synthesis,
topically
relationships,
synonyms
“car”
“vehicle”,
substitute
whereas
“drive”
(note
substituting
“car”).
including,
recommender
analytics.
enrich
queries,
inexact
unsupervised
efﬁciently
effectively.
fundamen-
advantages:
unsupervised,
no/little
language.
principled
changing
3)
Updating
update
co-occurrence
statistics,
“never-ending
growth”
manner.
relational
effort.
generality
scalability,
knowledge.
2014
IEEE
International
978-1-4799-5666-1/14/$31.00
©2014
549
Authorized
licensed
Illinois.
Downloaded
08,2022
01:57:44
UTC
Xplore.
Restrictions
apply.
RELATED
WORK
community,
proaches
work[7]).
rules,
acquired
limited,
embedding
[3],
[11])
expensive.
Earlier
[10],
[4],
Bullinaria
Levy
word-word
co-occurrence.
SVD
signiﬁcantly.
consuming,
unable
sequence-based
opinosis
summarization
allows
edges
immediately
Besides,
before.
detection
[15]
graph-based
[8].
pool
yet
III.
ADJACENCY
GRAPH
graph,
induced
“word”
unit
whatever
entities)
“words”
graph.
{v1,v2,...,
vN},
vi(1
⩽
N)
ordered
elements.
paragraph
sequence,
sequences.
si
⟨vi1,vi2,...,vil⟩,
vij
(1
elements
si.
And
sequences,
{s1,s2,...,sn}.
Subsequence
sp
sq
(sp
⟨vp,1,
vp,2,
vp,lp⟩,
⟨vq,1,
vq,2,
vq,lq⟩),
holds
subsequence
sq)
lp
lq
integer
vp,1
vq,r,
vp,2
vq,r+1,
...
vp,lp
vq,r+lp−1.
measure.
Nodes
(words
data).
immediate
non-immediate
edges.
adjacency,
restricted
neighbors,
co-occurrences
nodes
edge.
Gk
way:
node
Vk,
S.
s′
⟨vi,vr1,vr2,...,
vrk−1,vj⟩
(vi,vj)
vi
vj
w[(vi,vj)]
∣{s′∣s′
⟨vi,vr1,vr2,...,vrk−1,vj⟩
∧
s}∣.
Ek.
⟨vi,vj⟩
vj.
IV.
RANDOM
WALKS
G,
deﬁned,
forward
walking
backward
walking.
(vr1,
vr2),
(vr2,
vr3),
,(vrl,
vrl+1)
G.
vr1
→
vr2...
vrl+1
visit
vr1,
vr2,...,
sequentially.
⇢
vrl...
vrl+1,
vrl,...,
inverse
direction
transition
states.
paths,
paper),
subgraphs.
l-step
l→
{vi
vrl−1
vj∣(vi,vr1),...,(vrl−1,vj)
E}
l⇢
vj∣(vr1,vi),...,(vj,vrl−1)
E}.
PG(vi
vj)
vj).
vj),
diagonal
DF
DB.
A(i,j)
w[(vi,vj)],
(i,
i)
∑
∣V
∣
A(i,
DB(i,
A(j,
550
Vi
Vw
Vu
Vj
(a)
(b)
trip
Clockwise
trip;
Anti-clockwise
trip.
(i,j)
DB(i,j)
≠
TB
A,
DBAT
Pg(vi
1→
1⇢
TB(i,j).
1-step
walking,
multi-step
iteratively:
vr∈V
l−1
vr)
⋅
PG(vr
B(i,
MINING
PARADIGMATIC
SYNTAGMATIC
RELATIONS
Be-
elegantly
“round
trip”
walks.
Paragmatic
trips,
clockwise
anti-clockwise
reachable
vu
vw
conditions:
PG(vu
vi)
vw)
PG(vj
1(a))
anti-
1(b)).
vw,
vertical
ends
horizontal
ends.
↺
{vu∣PG(vu
0}
{vw∣PG(vi
W,
vu∈U
vw∈W
PG(vw
vu)
Strong
complish
walk.
∣U∣
∣W∣
enough,
matter
substitutable
tackle
problem,
normalize
trips
direction,
∣U∣⋅∣W∣.
reﬂects
correlated
substitutable.
walker
trip,
have:
l=0
αl,
max
allowed
αl
chose
short-distance
reliable,
αl.
equally
favored
regardless
path
length,
non-negative
∑s
Combining
together,
Pr(vi,vj)
Pr(vi,
k=1
βk
PGk(vi
⩾
choosing
walk,
∑K
B.
Syntagmatic
correlation
round
vj,
one-way
dominated
“popular”
outlinks
inlinks
node,
paths
back.
advance
destination
(considering
paths)
is:
G(vi
�→
l=1
∑vj′
∈V
vj′)
PG(vj′
∝
(6)
551
α
backward-ﬁrst
←�
(7)
high,
predecessor,
relatedness
successor.
“more”
“than”,
“much”.
graphs,
Syn(vi
Gk(vi
(8)
←
(9)
Relevance-Based
Victor
Lavrenko
Center
Intelligent
Comupter
Massachusetts,
Amherst,
MA
01003
lavrenko,croft
✁
@cs.umass.edu
classical
emerging
obstacle
class.
estimating
addressing
synonymy
polysemy.
outper-
TDT
tracking
developments
Re-
marked
departure
emergence
frameworks,
[16].
[5,
21,
10],
adopted
framework,
introducing
reﬁnements
expansion
abandon
attempting
During
respective
[19,
17,
22]
conceptually
plicitly
classify
purposes,
SIGIR’01,
September
9-12,
2001,
Orleans,
Louisiana,
2001
1-58113-331-6/01/0009
superﬁcial,
important.
frameworks
rich
[22]),
room
niques
[16]
augmenting
[15])
adjust-
suited
summariza-
answering
(TDT)
[25,
12]
segmentation
indica-
relevant.
troduce
resulting
query-based
tasks:
remainder
relevance-based
cross-entropy,
accuracy.
vide
owe
class
direc-
highlighting
connections
two.
2.1
Classical
Underlying
Robert-
son
[19],
✂
odds
class:
✄
☎
✞
✠
✡
☞
✎
Forum
260
2017
Hiemstra
ﬁed
differs
Binary
Independence
23]
treats
vec-
tor
space,
ignoring
frequencies.
viewed
multiple-Bernoulli
✆
☛
✌
absence
formation.
2-Poisson
[18]
goes
frequencies
Poisson
distributions.
multiple-
Inference
Network
feed-forward
belief
parame-
ters
aside,
vant
attempt
Modeling
viewing
strings
ument
✏
:
calculation
[15,
vocabulary,
Bernoulli
✒
(1).
dividual
probabilities.
intricately
non-parametric
Accurate
esti-
stumbling
block
train-
Miller
Song
[21],
[10]
vector,
✕
✗
✙
[16]).
frequen-
cies
representation,
formal-
ism.
Berger
transla-
[7]
synthetic
drawback
requirement
estimation.
noting
rudimentary
nent
non-diagonal
word-for-word
performs
expansion,
[5].
shift
trying
notable
Detection
Tracking
[12,
25,
26]
stories.
title
RELEVANCE
MODEL
mechanism
termines
obstacles
Estimating
envi-
ronment
data:
indication
Faced
estimates
interpret.
easier,
plenty
non-relevant.
justiﬁed
able.
probabil-
ities
smoothing.
user.
advocated
serts
achieved
✚
261
doc
rel
Queries
Note:
[19]
indepen-
dence
23],
(2010)
247–375
M.
Sanderson
10.1561/1500000009
248
Initial
Development
254
256
258
2.3
2.4
Challenging
Assumptions
266
2.5
Assessor
Consistency
267
2.6
Practical
Creating
269
Ad
Hoc
275
Building
277
Classic
Tracks
Uses
285
Exercises
286
TREC’s
Run
287
3.6
Hoc:
Great
Success
Qualiﬁcations
3.7
290
Post
291
292
294
Are
Equal?
304
Summing
Up
306
Beyond
Mean:
Signiﬁcance
308
Tests
310
Examining
Methodologies
319
Re-checking
320
Does
Pooling
Build
Unbiased
Sample?
322
Pools
Eﬃciently
325
Best
Eﬀectiveness
Measure?
334
Do
Predict
Behavior?
337
Conclusions
340
Alternate
Needs
342
Logs
344
Live
Labs
346
349
Acknowledgments
351
353
Index
375
School,
Sheﬃeld,
UK
m.sanderson@shef.ac.uk
assess
eﬀective-
origins
dating
1950s.
Across
nearly
started,
facto
monograph
devised
experimentation.
examinations
outlining
trends
logs
live
labs.
core,
modern-day
structures
pioneering
1950s
1960s
conceived
of.
tutorial
age,
valued
tool
examination
opening
pages
books
organizing
[210];
diﬀer-
materials
searched
[286].
stress
typing
(DB)
[262,
244].
constant,
incomplete
underspeciﬁed
issued
receiving
ﬁll
gaps
“nuclear
waste
dumping”
academic
repository
probably
detail,
he/she
prefers
reputable
sources,
enters
querying
“BBC”
oﬃcial
home
corpo-
ration,
request
letters
entered.
249
words)
senses,
concept,
locat-
DB
deterministic,
predicted
conducted;
sequently,
Retrieval.1
hopefully
list.
aﬀected
Keen
[61,
4]
ﬁve.
“The
withhold
demand
time)
physical
presentation)
eﬀort,
demanded
eﬀort).”
e.g.:
specifying
need;
interplay
rithm
composed;
searched;
haven’t
devise
non-empirical
[197]
elusive.
250
issued;
eventual
sought.
usability
face;
use;
eﬃciency,
cost,
eﬀectiveness
system:
determining
items,
engine,
assessed
conjunction
writing,
conferences
meetings
purely
use:
international
conferences,
CLEF,
NTCIR,
1990s.
decades
tradition
sharing
environments
decades,
inspired
innovative
identiﬁer,
docid;
queries);
id
(qid);
(often
qrels
set)
composed
qid/docid
detailing
possession
developer
researcher
loads
submits
one-by-one.
docids
concatenated
run.
deter-
251
Together,
simulation
setting.
isola-
helping
failure,
commonly,
Either
rival
contrasted.
determinations,
implica-
deployed
innovation
recognition
crucially
collections.2
Through
sharing,
beneﬁted
(sub-
stantial)
re-using
Shared
exercises.
Exper-
iments
constituted
validating
short,
catalyst
community.
steady
stream
Salton’s
[210,
5]
document;
Van
Rijsbergen’s
[262]
another;
Sp¨arck
Jones’s
[242]
third.
works,
writ-
ten;
Hearst
[116,
3].
(HLT)
discipline
environments.
HLT,
252
evaluation:
exercise
outlined
[280];
Management
reﬂected
[98];
Journal
American
Society
spective
[253].
recently,
[199].
ﬁll.
music,
speech,
chemical
structures,
monograph,
similarly
queried
text;
although,
steps
1950s,
priorities
researchers.
Often
vice
versa.
laid
chronological
periods,
exercise,
TREC.
1950s–early1990s,
2:
develop-
catalogue
full-text
news-
strongly
search:
possible.
1990s–early
2000s,
3:
“TREC
hoc”
period.
Scale
standardization
decade.
laborated
253
2000s–present,
4:
(for
name).
Reﬂecting
ever-growing
searched,
diversiﬁcation
preference
gathered
exercises
fostered
period:
Apart
[74],
area,
survey.
spread
location.
Note,
explicitly
stated
author.
genesis
1960s.
How-
ever,
career,
[60]
collaborator,
Thorne,
1953.
intention
librarians
locating
cataloguing
faced
requests
Thorne
completed
[257].
resonance
motivations
today.
‘yardstick’
assist
assessing
merits
fertile
assessments
eﬃciency
libraries”.
“Suppose
[from
users]
entered
log,
believed
log.
255
lection,
catalogue’s
success”.
illustrate,
Appendix
nose
revolution
ﬁne-
angles
attack
0◦
8◦
subsonic
Mach
(RN
×
10◦).”
catalogued
library.
Assessments
item,
consideration
costs
writings,
(though
Thorne’s
eﬀorts,
Gull
(who
1956,
[97])
Composed
entries,
total,
98
Gull)
ble.
independently,
proved
problematic,
liberal
(Cleverdon
[60],
seeing
qrels,
centralize
collections.)
catalogues.
mention
“machines”
Kent
[155],
system”.
Maron
experimenting
110
Fels
[84]
Mooers
[181].
Bryant
[35]
Borko
[29]
who,
Bryant,
612
abstracts.
appendix
[195]
tests;
[159]
late
1940s,1
clearly
priority
how-
remembered
today’s
reﬂective
piece,
editorial
Doc-
umentation2
(now
renamed
JASIST)
stating
“evaluation
[IR]
systems”.
wasn’t
Con-
funded
[57].
man-
built,
1,200
“search
questions”.
Holmstrom
“machine
Univac”
capable
refer-
code.
code
magnetic
steel
tape.
“at
120
minute”
[123].
UNIVAC
isn’t
existence
1951,
sold,
saw
pre-production
creator
mechanical
twentieth
century
1955,
Truth,
Whole
Truth.
”
Documentation.
58;
editorial.
257
papers;
retrieved,
success.
became
ensuring
measurements
reliable.
1,400
“documents”
(titles,
names,
abstracts)
papers.
contacted
addressed,
1–5
references.
checked
asking
comprising
judgments.
insti-
gated
collections:
(named
built).
1968,
Lesk
[164],
ADI,
papers,
IRE-3
Yu
[215]
more:
Time
425
magazine;
450
MEDLARS
[158]
extensive
410
NPL
Vaswani
Cameron
[263].
[246].
Name
Docs.
Qrys.
Year3
THE
PROBABILITY
RANKING
PRINCIPLE
IN
ROBERTSON
Library,
Archive,
Studies,
London
principle
Cooper.
justified
assumptions,
hold,
valid.
lie
rest.
decides
document-by-document
REFERENCE
request,
Kuhns.1
definitive
used;
Kuhns
accept
priori.
interpreted.
BACKGROUND
Kuhns's
dis­
certainty
requester
dealing
probabilities;
accordingly.
confuses
Robertson).2
satisfied
document:
usual
'relevance'.
usefulness,
satisfaction)
basic,
dichotomous
variable,
outside
dichotomy
certainly
valid;
elsewhere.2,3
below.
(essen­
tially
probabilistic)
Documentation,
33,
1977,
pp.
294-304
1977
him
first.
Kuhns.
Cooper4
prin­
ciple:
(PRP):
system's
response
decreasing
purpose,
obtainable
Cooper
counter-examples
PRP
constructed:
less-than-optimal
performance.*
Elsewhere,3
PRP,
justification
assumptions.
justifications.
re­
mainder
assump­
Cooper's
taken.
CRITERION
VARIABLE
predict,
answer.
itself,
variable?
already
indicated
dichotomous:
in-between
implicitly
assumption.
problem:
Cooper,
'expected
utility',
docu­
useful­
another?
B
(=
first)
use­
fulness
repeats
pro­
Fourth,
problem;
unequivocally
simplifying
assumptions:
*
published,
counter-example
295
JOURNAL
DOCUMENTATION
depend
seen,
be).
raise
relevance.
below;
mean­
PRP.
FIRST
JUSTIFICATION:
TRADITIONAL
MEASURES
prove
para­
meters
effectiveness.
proof
elsewhere.3
concerning
events
a,
(ā
event
'not
a').
Bayes's
theorem
Similarly:
Hence:
log-odds)
prob­
ability,
Lemma:
interest.
partially
order)
cut-off
(Various
surveyed
Cooper;5
con­
sidered
below.)
are:
296
θ1
P(document
retrieved|document
relevant)
θ2
non-relevant)
ɸ
relevant|
retrieved)
γ
relate
request—indeed
fallout,
(where
requests);
matters
parameters,
relating
request:
θ1(di)
di|
θ2(di)
ɸ(di)
di)
P(di
Also
lemma,
(In
exp
[logit
—logit
γ])
θ2,
(maximize
xi—that
ɸ(di).
maxi­
mum
reached.
minimized
ordering.
lemma
again:
297
mentioned.
extend
Cooper's6
optimizes
per­
formance.
that:
formalism
§2,
rele­
relates
request;
requests.
SECOND
DECISION
THEORY
'correct'
dictates
else­
where.7
'loss
function'
Loss
(retrieved|
α1
(that
α1),
(not
retrieved|relevant)
notation
(loss-minimizing)
if:
or:
order,
α/(α2
α1).
consideration.
generalize
somewhat,
supposing
§2)
az
diminishes
search;
recalcu-
298
stopping
a1/(a2
a1).
decision-theoretic
conditions.
Again
§2;
DIFFERENT
fail?
Cooper,4
cumulating
requests,
invalidates
§3,
request;*
§4,
request.
document-by-document,
request-by-request.
ciple
request-by-request
informally
deals
fails,
limitations.
'satisfaction'.
searches
obtained;
exclude,
'frustration-point'
Cooper's5
terms).
dichotomous.
Digger8
experi­
ments).
request-based
document-by-document;
situation,
ridiculously
clumsy
rankings.†
second:
accepting
'micro-average'
etc.—that
documents—for
level.
dubious
inadequate
points.
†
Stirling10
analysed
devising
so.
time-consuming,
unusable
Stirling
docs,
299
maximal
examples4),
receives
fall
groups:
need-groups
belongs
(assume
2/3),
(d1-d3)
him,
wants
them;
second,
(d4)
wants.
A:
d1,
d2,
d3,
d4
B:
d4,
d3
plot
rank—
problem—say
lently
bounded
lines
arithmetic
fallout:
rather,
requests)
cut-off.
principle:
rank;
equivalently,
minimize
(averaged
(micro-averaged
requests).
noted,
to)
events.
valuable
quick
cost-to-the-organization
reflect
user-perceived
dilemma
resolvable:
circumstances
criterion.
use,
reasons
earlier:
satisfaction-point
searches;
efficient
shed
DOCUMENT-BY-DOCUMENT
bring
maintaining
character?
themselves.
need-group
satisfaction,
utility.
d1-d3
1/3
need-group;
need-group.
Expected
yields
Cooper's.
d1-d3.
suggests:
'right'
recalculating
modification,
destroys
document-
by-document
character
301
modifications
lems:
modifications,
docs
do,
bridging
beginning
useful.
prediction
formalize.
Cooper's4
estima-
'probability
relevance'
prediction.
Going
definition,
questions:
pre­
diction?
utilize
informa­
tion?
represent,
retrieval)
ultimately
(explicit
implicit)
hypothesis.
Jones9
Cluster
Hypothesis:
matches
Hypothesis
incorporated
presence
cluster
detecting
clusters,
membership
operations
fashion.
theorist
my
Goffman11
dependence
Rijs­
bergen
Goffman's
performance).
302
CONCLUSIONS
Whether
par­
ticular,
probability-ranking
dependency-oriented
cluster-based
priority.
REFERENCES
MARON,
KUHNS,
L.
Computing
Machinery,
1960,
216-44.
ROBERTSON,
Management,
1971,
247151.
Ph.D.
thesis,
London,
1976.
COOPER,
s.
suboptimality
usefulness.
(Private
communication.)
selecting
24,
1973,
87-100
413-24.
length:
weak
19,
30-41.
ans
SPARCK
JONES,
K.
1976,
129-46.
KEEN,
DIGGER,
Report
test.
Librarianship
Wales,
Aberystwyth,
1972.
VAN
RIJSBERGEN,
251-7.
STIRLING,
performance:
rule.
12,
1975,
105-6.
11.
GOFFMAN,
trieval,
1969,
361-73.
CROFT,
method.
327—31.
APPENDIX
W
Cooper.4
303
Consider,
(associated
request)
sub-classes,
U1
U2;
twice
U2:
Any
D1-D9,
U2
D10,
own,
⅔
satis­
fying
puts
D10
⅓
him/her;
D1-D9
receive,
nine
readily
D1(say)
D2-D9
second.
optimal.
counter-example.
anyway:
themselves,
prompting
'see
also'
heading.
remains:
people,
§6
§5
(Received
DECADES
LANGUAGE
MODELING:
WHERE
DO
WE
GO
FROM
HERE?
Ronald
Rosenfeld
roni@cs.cmu.edu
phenomena
technologies.
1980,
art.
directions,
argue
integration
OUTLINE
(SLM)
regularities
im-
proving
appli-
cations.
linguis-
units,
va-
riety
SLM
start),
trans-
lation,
optical
charac-
recognition,
handwriting
recogni-
spelling
correction,
more.
rule-based
beneﬁcial
statistical/information
employs
categorical
language,
vocabularies
rally
consequently
critically
Over
twenty
successively
quality
increased
dramatically.
asymptote.
accumulate
will,
web),
currently
factor.
informal
IBM
bigram
saturate
hundred
million
trigram
billion
Ironically,
pop-
ular
-grams)
modeled
–
symbols,
structure,
impoverished
-grams
succeeded
stymied
proponent
Fred
Jelinek,
‘put
modeling’
modestly
successful.
provement
overviews
estab-
teractive
integra-
encoding
facing
ﬁeld.
MODELING
����
instructive
linguistics.
Admittedly,
communities)
fuzzy
boundaries,
overlap.
Nonetheless,
surface
form,
(i.e.
tree,
etc.).
mating
Pr
�
feasible.
play
acoustic
signal

spoken.
��

�
!"
��
�$�
%�&amp;�'�$�
plays
belongs.
(say)
�,$�
.$.$.,
�0/1�
�32
constructed.
classi-
ﬁer,

4
5"
�8
�8%��
like-
lihood.
fashion,
nique,
1Or
spoken
utterances,
unit.
Average-Log-Likelihood
��9
�&lt;;
�&gt;=1?A@CB
D�8EF��9
?
9G
9�,
9H-
�.$.$.
9JI#2
sample,
M
entropy
unknown)
�0E
cross-entropy
���K3�
�LNM
=PO
��'9�
%RQ'SRTU�
�'9�
Actual
[6]:
VXW

@
ZY\[P]0���K3�
�^_
`ba
aedgf
Perplexity
(geometric)
branching
perplexity).
entropy,
complexity,
Ultimately,
designed,
application.
rates
poorly
Lower
rates,
counterexamples
rough
thumb,
5%
prac-
tically
signiﬁcant;
10%–20%
noteworthy,
always)
translates
30%
rare!).
perplex-
ity,
met
preferred
metric
construction.
details,
Known
drastic
by,
system).
Evidence
sources:
Brittleness
domains:
Current
mod-
style,
genre
trained.
casual
phone
conversations,
off
transcripts
conversa-
140
TV
radio
broadcasts.
human:
Dow-Jones
doubled
Associated
([8,
220]).
False
assumption:
tractable,
por-
monly
-gram,
ity
iden-
tity
-1
Yet
cursory
patently
false.
overly
sharp
hap-
pening
classiﬁcation:
equa-
sharp,
reaching
posterior,
ﬁcation
Shannon-style
experiments:
Claude
Shannon
pioneered
eliciting
10].
English.
formulated
gambling
setup
1980s,
‘Shannon-style’
correcting
Shannon-
style
searchers.
[12]
aimed
improve-
areas.
easily,
routinely
stantially.
apparently
reasoning
linguistic,
sense,
levels.
SURVEY
MAJOR
TECHNIQUES
niques.
treatment,
Almost
decompose
ities:
�'�$�
def

�'h,
.$.$.
h!I1�
?kj
��h
th
hn-
.�.$.
?�o
,p2
staple
prod-
ucts
-gram.
-gram
reduces
dimensionality
-1:
��'h
q4��'h
IZr8,
$.�.$.3
trades
variance)
appropriateness
bias).
=3)
pora
(millions
=2)
ones.
Deriving
sparse
corpora.
trigrams
consecutive
triplets)
words’
newspaper
ar-
ticles,
[8,
8].
ob-
served
trigrams,
occurred
once,
counts.
(ML)
gram
advisable.
Instead,
developed.
discounting
ML
[14,
15],
recursively
backing
interpolating
[19].
variable-length
[20,
23,
lattice
[25].
Much
[26].
addition,
toolkits
disseminated
[27,
30].
battle
sparseness
to.
trigram:
�'h!t
h,
hn-3�u
t�
hn-p�
3s
-p�
(10)
